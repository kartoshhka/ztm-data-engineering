{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ce2631-b840-4a7f-8183-fc50cb1977ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark aggregation functions\") \\\n",
    "    .config(\"spark.python.worker.faulthandler.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.execution.pyspark.udf.faulthandler.enabled\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078a3193-f1a5-4e85-b50a-f80cf5908b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- listing_url: string (nullable = true)\n",
      " |-- scrape_id: long (nullable = true)\n",
      " |-- last_scraped: date (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- neighborhood_overview: string (nullable = true)\n",
      " |-- picture_url: string (nullable = true)\n",
      " |-- host_id: integer (nullable = true)\n",
      " |-- host_url: string (nullable = true)\n",
      " |-- host_name: string (nullable = true)\n",
      " |-- host_since: date (nullable = true)\n",
      " |-- host_location: string (nullable = true)\n",
      " |-- host_about: string (nullable = true)\n",
      " |-- host_response_time: string (nullable = true)\n",
      " |-- host_response_rate: string (nullable = true)\n",
      " |-- host_acceptance_rate: string (nullable = true)\n",
      " |-- host_is_superhost: string (nullable = true)\n",
      " |-- host_thumbnail_url: string (nullable = true)\n",
      " |-- host_picture_url: string (nullable = true)\n",
      " |-- host_neighbourhood: string (nullable = true)\n",
      " |-- host_listings_count: integer (nullable = true)\n",
      " |-- host_total_listings_count: integer (nullable = true)\n",
      " |-- host_verifications: string (nullable = true)\n",
      " |-- host_has_profile_pic: string (nullable = true)\n",
      " |-- host_identity_verified: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- neighbourhood_cleansed: string (nullable = true)\n",
      " |-- neighbourhood_group_cleansed: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- accommodates: integer (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- bathrooms_text: string (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- beds: integer (nullable = true)\n",
      " |-- amenities: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- minimum_nights: integer (nullable = true)\n",
      " |-- maximum_nights: integer (nullable = true)\n",
      " |-- minimum_minimum_nights: integer (nullable = true)\n",
      " |-- maximum_minimum_nights: integer (nullable = true)\n",
      " |-- minimum_maximum_nights: integer (nullable = true)\n",
      " |-- maximum_maximum_nights: integer (nullable = true)\n",
      " |-- minimum_nights_avg_ntm: double (nullable = true)\n",
      " |-- maximum_nights_avg_ntm: double (nullable = true)\n",
      " |-- calendar_updated: string (nullable = true)\n",
      " |-- has_availability: string (nullable = true)\n",
      " |-- availability_30: integer (nullable = true)\n",
      " |-- availability_60: integer (nullable = true)\n",
      " |-- availability_90: integer (nullable = true)\n",
      " |-- availability_365: integer (nullable = true)\n",
      " |-- calendar_last_scraped: date (nullable = true)\n",
      " |-- number_of_reviews: integer (nullable = true)\n",
      " |-- number_of_reviews_ltm: integer (nullable = true)\n",
      " |-- number_of_reviews_l30d: integer (nullable = true)\n",
      " |-- availability_eoy: integer (nullable = true)\n",
      " |-- number_of_reviews_ly: integer (nullable = true)\n",
      " |-- estimated_occupancy_l365d: integer (nullable = true)\n",
      " |-- estimated_revenue_l365d: integer (nullable = true)\n",
      " |-- first_review: date (nullable = true)\n",
      " |-- last_review: date (nullable = true)\n",
      " |-- review_scores_rating: double (nullable = true)\n",
      " |-- review_scores_accuracy: double (nullable = true)\n",
      " |-- review_scores_cleanliness: double (nullable = true)\n",
      " |-- review_scores_checkin: double (nullable = true)\n",
      " |-- review_scores_communication: double (nullable = true)\n",
      " |-- review_scores_location: double (nullable = true)\n",
      " |-- review_scores_value: double (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- instant_bookable: string (nullable = true)\n",
      " |-- calculated_host_listings_count: integer (nullable = true)\n",
      " |-- calculated_host_listings_count_entire_homes: integer (nullable = true)\n",
      " |-- calculated_host_listings_count_private_rooms: integer (nullable = true)\n",
      " |-- calculated_host_listings_count_shared_rooms: integer (nullable = true)\n",
      " |-- reviews_per_month: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listings = spark.read.csv(\"../data/listings.csv.gz\", \n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\", \n",
    "    quote='\"',\n",
    "    escape='\"', \n",
    "    multiLine=True,\n",
    "    mode=\"PERMISSIVE\" \n",
    ")\n",
    "listings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32095599-a1da-408e-b315-3e0481e8bb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- listing_id: long (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- reviewer_id: integer (nullable = true)\n",
      " |-- reviewer_name: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews = spark.read.csv(\"../data/reviews.csv.gz\", \n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\",\n",
    "    quote='\"',\n",
    "    escape='\"',\n",
    "    multiLine=True,\n",
    "    mode=\"PERMISSIVE\"\n",
    ")\n",
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5fc7ba-8be1-4680-aaf1-6724d1399e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "| category|count|\n",
      "+---------+-----+\n",
      "|Mid-range|28108|\n",
      "|   Budget| 6612|\n",
      "|   Luxury|27964|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. For each listing compute string category depending on its price, and add it as a new column.\n",
    "# A category is defined in the following way:\n",
    "#\n",
    "# * price < 50 -> \"Budget\"\n",
    "# * 50 <= price < 150 -> \"Mid-range\"\n",
    "# * price >= 150 -> \"Luxury\"\n",
    "# \n",
    "# Only include listings where the price is not null.\n",
    "# Count the number of listings in each category\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "listings = listings.withColumn('price_numeric', regexp_replace('price', '[$,]', '').cast('float'))\n",
    "\n",
    "# TODO: Implement a UDF\n",
    "@F.udf(StringType())\n",
    "def categorize_listing_price_udf(price_num):\n",
    "    if price_num is None:\n",
    "        return 'Unknown'\n",
    "    elif price_num < 50:\n",
    "        return 'Budget'\n",
    "    elif 50 <= price_num < 150:\n",
    "        return 'Mid-range'\n",
    "    elif price_num >= 150:\n",
    "        return 'Luxury'\n",
    "    return 'Unknown'\n",
    "# TODO: Apply the UDF to create a new DataFrame\n",
    "\n",
    "listings_categorized = listings \\\n",
    "    .filter(listings.price_numeric.isNotNull()) \\\n",
    "    .withColumn('category', categorize_listing_price_udf(listings.price_numeric)) \\\n",
    "    .select('id', 'name', 'price', 'category') \\\n",
    "    .groupby('category') \\\n",
    "    .count() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69b6d82e-6255-40bb-be8f-837c0cef6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|                name|avg_sant_score|\n",
      "+--------------------+--------------+\n",
      "|Central and Cozy ...|           6.0|\n",
      "|Boutique 3bd Lond...|           6.0|\n",
      "|Tranquil terraced...|           6.0|\n",
      "|London NW3. Feel ...|           5.0|\n",
      "|Canal Side stylis...|           5.0|\n",
      "|Twickenham double...|           5.0|\n",
      "|Luxury Holiday Le...|           5.0|\n",
      "|Luxury  Modern  S...|           5.0|\n",
      "|     Heart of Fulham|           5.0|\n",
      "|Light-filled 1 be...|           5.0|\n",
      "|Gorgeous family h...|           5.0|\n",
      "|Modern cozy room ...|           5.0|\n",
      "|Spacious Victoria...|           5.0|\n",
      "|Bright&cosy flat ...|           5.0|\n",
      "|Bright Battersea ...|           5.0|\n",
      "|Impressive Flat i...|           5.0|\n",
      "|Charming Period o...|           5.0|\n",
      "|Beautifully Conte...|           5.0|\n",
      "|   Home Sweet home !|           5.0|\n",
      "|Maison Blooms-Lux...|           5.0|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# 2. In this task you will need to compute a santiment score per review, and then an average sentiment score per listing.\n",
    "# A santiment score indicates how \"positive\" or \"negative\" a review is. The higher the score the more positive it is, and vice-versa.\n",
    "#\n",
    "# To compute a sentiment score per review compute the number of positive words in a review and subtract the number of negative\n",
    "# words in the same review (the list of words is already provided)\n",
    "#\n",
    "# To complete this task, compute a DataFrame that contains the following fields:\n",
    "# * name - the name of a listing\n",
    "# * average_sentiment - average sentiment of reviews computed using the algorithm described above\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "# Lists of positive and negative words\n",
    "positive_words = {'good', 'great', 'excellent', 'amazing', 'fantastic', 'wonderful', 'pleasant', 'lovely', 'nice', 'enjoyed'}\n",
    "negative_words = {'bad', 'terrible', 'awful', 'horrible', 'disappointing', 'poor', 'hate', 'unpleasant', 'dirty', 'noisy'}\n",
    "\n",
    "# TODO: Implement the UDF\n",
    "def sentiment_score(comment):\n",
    "    if comment is None:\n",
    "        return 0\n",
    "    comment_lower = comment.lower()\n",
    "    pos_score = sum(1 for word in positive_words if word in comment_lower)\n",
    "    neg_score = sum(1 for word in negative_words if word in comment_lower)\n",
    "    return float(pos_score - neg_score)\n",
    "\n",
    "sentiment_score_udf = F.udf(sentiment_score, FloatType())\n",
    "\n",
    "reviews_with_sentiment = reviews \\\n",
    "  .withColumn(\n",
    "    'santiment_score',\n",
    "    sentiment_score_udf(reviews.comments)\n",
    "  )\n",
    "\n",
    "# TODO: Create a final DataFrame\n",
    "final_df = listings \\\n",
    "    .join(reviews_with_sentiment, listings.id == reviews_with_sentiment.listing_id, how='inner') \\\n",
    "    .groupBy('listing_id','name') \\\n",
    "    .agg(F.round(F.avg(F.col('santiment_score')), 2).alias('avg_sant_score')) \\\n",
    "    .orderBy(F.desc('avg_sant_score'))\n",
    "\n",
    "final_df.select('name', 'avg_sant_score').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "637b15b2-66df-4e9b-9bc1-8ba328e14aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+----------------------+-------------+\n",
      "|        listing_id|                name|average_comment_length|reviews_count|\n",
      "+------------------+--------------------+----------------------+-------------+\n",
      "|618608352812465378|Beautiful Georgia...|    1300.1666666666667|            6|\n",
      "|          28508447|The warm and cosy...|    1089.3333333333333|            6|\n",
      "|627425975703032358|Superb loft beaut...|     951.7777777777778|            9|\n",
      "|           2197681|Luxurious apartme...|                 939.2|            5|\n",
      "|          13891813|Beautiful 2 Bedro...|                 905.0|            5|\n",
      "|            979753|Pop-Art Brand New...|     893.9230769230769|           13|\n",
      "|630150178279666225|Georgian oasis of...|     890.7272727272727|           11|\n",
      "|           8856894|Beautiful period ...|     890.1666666666666|            6|\n",
      "|          29469389|  London Single home|                 885.0|            6|\n",
      "|          22524075|Large 3 bed 2 bat...|                 885.0|            5|\n",
      "|           5555679|Charming, Comfort...|     878.7169811320755|          106|\n",
      "|          33385444|Superb penthouse ...|                 848.0|            5|\n",
      "|            565214|Beautiful 4-bedro...|     834.0833333333334|           12|\n",
      "|          53493254|âœª COZY AMAZING FL...|                 831.0|            7|\n",
      "|          12646480|Stunning Tower Br...|                 819.6|            5|\n",
      "|          17997858|Private room, pri...|               816.875|            8|\n",
      "|           8574525|Beautiful 3 bedro...|     813.6666666666666|            6|\n",
      "|          38664252|Beautiful 1 Bed A...|     805.8333333333334|            6|\n",
      "|          16308170|Bright 1 BR (4 mi...|     799.6666666666666|            6|\n",
      "|546424544012965343|The Chelsea Sapphire|               772.625|            8|\n",
      "+------------------+--------------------+----------------------+-------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# 3. Rewrite the following code from the previous exercise using SparkSQL:\n",
    "#\n",
    "# ```\n",
    "# from pyspark.sql.functions import length, avg, count\n",
    "# \n",
    "# reviews_with_comment_length = reviews.withColumn('comment_length', length('comments'))\n",
    "# reviews_with_comment_length \\\n",
    "#   .join(listings, reviews_with_comment_length.listing_id == listings.id, 'inner') \\\n",
    "#   .groupBy('listing_id').agg(\n",
    "#       avg(reviews_with_comment_length.comment_length).alias('average_comment_length'),\n",
    "#       count(reviews_with_comment_length.id).alias('reviews_count')\n",
    "#   ) \\\n",
    "#   .filter('reviews_count >= 5') \\\n",
    "#   .orderBy('average_comment_length', ascending=False) \\\n",
    "#   .show()\n",
    "# ```\n",
    "# This was a solution for the the task:\n",
    "#\n",
    "# \"Get top five listings with the highest average review comment length. Only return listings with at least 5 reviews\"\n",
    "\n",
    "reviews.createOrReplaceTempView(\"reviews\")\n",
    "listings.createOrReplaceTempView(\"listings\")\n",
    "\n",
    "# Write the SQL query\n",
    "sql_query = \"\"\"\n",
    "SELECT\n",
    "    r.listing_id,\n",
    "    l.name,\n",
    "    AVG(LENGTH(r.comments)) AS average_comment_length,\n",
    "    COUNT(r.id) AS reviews_count\n",
    "FROM reviews r\n",
    "INNER JOIN listings l\n",
    "    ON r.listing_id = l.id\n",
    "GROUP BY r.listing_id, l.name\n",
    "HAVING COUNT(r.id) >= 5\n",
    "ORDER BY average_comment_length DESC\n",
    "\"\"\"\n",
    "\n",
    "spark \\\n",
    "  .sql(sql_query) \\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cd68c71-0ce8-4a21-be62-a822fce18522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------+\n",
      "|host_id|average_days_since_first_review_days|\n",
      "+-------+------------------------------------+\n",
      "|   6774|                  2040.1666666666667|\n",
      "|   9089|                               523.0|\n",
      "|   9323|                              3033.0|\n",
      "|  10657|                              2200.0|\n",
      "|  11431|                              3629.0|\n",
      "|  14596|                              2716.0|\n",
      "|  19195|                              3680.0|\n",
      "|  25235|                              3316.0|\n",
      "|  26258|                                88.0|\n",
      "|  30577|                              1007.0|\n",
      "|  30780|                              3317.0|\n",
      "|  32851|                              3550.5|\n",
      "|  34007|                               385.0|\n",
      "|  36808|                               787.0|\n",
      "|  38691|                              1014.0|\n",
      "|  40515|                              2276.0|\n",
      "|  40944|                   568.0833333333334|\n",
      "|  41759|                              5406.0|\n",
      "|  43039|                              4855.0|\n",
      "|  46014|                              2148.0|\n",
      "+-------+------------------------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# 4. [Optional][Challenge]\n",
    "# Calculate an average time passed from the first review for each host in the listings dataset. \n",
    "# To implmenet a custom aggregation function you would need to use \"pandas_udf\" function to write a custom aggregation function.\n",
    "#\n",
    "# Documentation about \"pandas_udf\": https://spark.apache.org/docs/3.4.2/api/python/reference/pyspark.sql/api/pyspark.sql.functions.pandas_udf.html \n",
    "#\n",
    "# To use \"pandas_udf\" you would need to install two additional dependencies in the virtual environment you use for PySpark:\n",
    "# Run these commands:\n",
    "# ```\n",
    "# pip install pandas\n",
    "# pip install pyarrow\n",
    "# ```\n",
    "\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import PandasUDFType\n",
    "import pandas as pd\n",
    "\n",
    "@pandas_udf(DoubleType())\n",
    "def average_days_since_first_review_udf(first_review_series: pd.Series) -> float:\n",
    "    # TODO: Implement the UDF\n",
    "    dates = pd.to_datetime(first_review_series)\n",
    "    days_passed = (pd.Timestamp('today') - dates).dt.days\n",
    "    if days_passed.empty:\n",
    "        return None\n",
    "    return days_passed.mean()\n",
    "\n",
    "listings \\\n",
    "  .filter(\n",
    "    listings.first_review.isNotNull()\n",
    "  ) \\\n",
    "  .groupBy('host_id') \\\n",
    "  .agg(\n",
    "    average_days_since_first_review_udf(listings.first_review).alias('average_days_since_first_review_days')\n",
    "  ) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7deb76-52b8-47a9-9968-748364b018ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
